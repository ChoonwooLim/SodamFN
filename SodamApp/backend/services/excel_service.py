import pandas as pd
import os
import datetime

# Hardcoded path for now, can be moved to config
EXCEL_PATH = r"C:\WORK\SodamFN\2025ì‹¤ì†Œë“ë¶„ì„\ì†Œë‹´ê¹€ë°¥ì†ìµê³„ì‚°ì„œ(9~12).xlsx"

class ExcelService:
    def __init__(self, file_path=None):
        self.file_path = file_path
        # Only check existence if a real path is provided (not None and not "dummy_path")
        if self.file_path and self.file_path != "dummy_path" and not os.path.exists(self.file_path):
            raise FileNotFoundError(f"Excel file not found at {self.file_path}")

    def get_monthly_summary(self):
        """
        Reads the 'ì¢…í•©' sheet and extracts monthly Revenue, Cost, and Profit.
        Returns a list of dictionaries for the frontend graph.
        """
        try:
            # Read 'ì¢…í•©' sheet, no header to rely on index
            df = pd.read_excel(self.file_path, sheet_name='ì¢…í•©', header=None)
            
            # Map columns to months based on our analysis
            # Col 4: Jul, 5: Aug, 6: Sep, 7: Oct, 8: Nov, 9: Dec
            # (0-indexed in pandas)
            month_map = {
                4: "7ì›”", 5: "8ì›”", 6: "9ì›”", 7: "10ì›”", 8: "11ì›”", 9: "12ì›”"
            }
            
            # Row indices (observed from analysis)
            # Revenue: Row 2 (Index 2) -> "ìˆ˜ì… ë§¤ì¥ ë§¤ì¶œ" + others. 
            # Actually Row 7 (Index 7) is "í•© ê³„" of Revenue?
            # Let's look at preview again.
            # Row 7: í•© ê³„ (Revenue Total)
            # Row 17: í•© ê³„ (Expense Total)
            # Row 18: ì˜ì—…ì´ìµ (Profit)
            
            revenue_row_idx = 7
            expense_row_idx = 17
            profit_row_idx = 18
            
            summary_data = []
            
            for col_idx, month_name in month_map.items():
                revenue = df.iloc[revenue_row_idx, col_idx]
                expense = df.iloc[expense_row_idx, col_idx]
                profit = df.iloc[profit_row_idx, col_idx]
                
                # Handle NaNs
                revenue = float(revenue) if pd.notna(revenue) else 0
                expense = float(expense) if pd.notna(expense) else 0
                profit = float(profit) if pd.notna(profit) else 0
                
                summary_data.append({
                    "month": month_name,
                    "revenue": int(revenue),
                    "expense": int(expense),
                    "profit": int(profit),
                    "margin": round((profit / revenue * 100), 1) if revenue > 0 else 0
                })
                
            return summary_data

        except Exception as e:
            print(f"Error reading Excel: {e}")
            return []

    def get_revenue_breakdown(self):
        """
        Extracts revenue sources (Store, Coupang, Baemin, etc.) for the latest month (Dec).
        """
        try:
            df = pd.read_excel(self.file_path, sheet_name='ì¢…í•©', header=None)
            
            # Row indices for channels (0-indexed from inspection)
            # Row 2: ë§¤ì¥ ë§¤ì¶œ
            # Row 3: ì¿ íŒ¡ ì •ì‚°ê¸ˆ
            # Row 4: ë°°ë¯¼ ì •ì‚°ê¸ˆ
            # Row 5: ìš”ê¸°ìš” ì •ì‚°ê¸ˆ
            # Row 6: ë•¡ê²¨ìš” ì •ì‚°ê¸ˆ
            channels = {
                "ë§¤ì¥": 2,
                "ì¿ íŒ¡": 3,
                "ë°°ë¯¼": 4,
                "ìš”ê¸°ìš”": 5,
                "ë•¡ê²¨ìš”": 6
            }
            
            # Target Month Column: 9 (December)
            target_col = 9 
            
            result = []
            for name, row_idx in channels.items():
                val = df.iloc[row_idx, target_col]
                val = int(val) if pd.notna(val) else 0
                result.append({"name": name, "value": val})
                
            return result
        except Exception as e:
            print(f"Error reading Revenue Breakdown: {e}")
            return []

    def get_top_expenses(self, month: int = 12):
        """
        Extracts top vendors by cost for a specific month.
        Default to December (12).
        
        Also joins with 'Vendor Info' sheet to get Item details.
        """
        try:
            # 1. Get Top Expenses from Cost Sheet
            sheet_name = f"{month}ì›”ë¹„ìš©"
            df = pd.read_excel(self.file_path, sheet_name=sheet_name, header=None)
            
            # Vendor Name: Col 0 (A)
            # Total Amount: Col 31 (AF) - Last column based on inspection
            
            # Slice from row 2 (skipping headers)
            vendors = df.iloc[2:, 0] 
            amounts = df.iloc[2:, 31] 
            
            data = pd.DataFrame({"vendor": vendors, "amount": amounts})
            
            # Clean data
            data = data.dropna(subset=['amount'])
            # Ensure amount is numeric
            data['amount'] = pd.to_numeric(data['amount'], errors='coerce').fillna(0)
            data = data.dropna(subset=['vendor']) # Drop if vendor is NaN
            data = data[data['amount'] > 0]
            
            # Group by Vendor
            grouped = data.groupby('vendor')['amount'].sum().reset_index()
            grouped = grouped.sort_values('amount', ascending=False)
            top_list = grouped.head(5).to_dict('records')

            # 2. Get Item Info from 'Vendor Info' Sheet
            vendor_info = self.get_vendors() # Returns dict {name: item}
            
            # 3. Merge Info
            result = []
            for item in top_list:
                v_name = item['vendor']
                v_item = vendor_info.get(v_name, "")
                result.append({
                    "vendor": v_name,
                    "amount": int(item['amount']),
                    "item": v_item
                })
                
            return result
            
        except Exception as e:
            print(f"Error reading Top Expenses: {e}")
            return []

    def get_vendors(self):
        """
        Reads 'ê±°ë˜ì²˜ì •ë³´' sheet and returns a dict mapping Vendor -> Item.
        If sheet doesn't exist, returns empty dict.
        """
        try:
            wb = load_workbook(self.file_path)
            if 'ê±°ë˜ì²˜ì •ë³´' not in wb.sheetnames:
                return {}
            
            df = pd.read_excel(self.file_path, sheet_name='ê±°ë˜ì²˜ì •ë³´')
            # Expecting columns: ['Vendor', 'Item']
            if df.empty:
                return {}
            
            return pd.Series(df.Item.values, index=df.Vendor).to_dict()
        except Exception as e:
            # print(f"Error reading Vendor Info: {e}")
            return {}

    def sync_vendors(self):
        """
        Scans all monthly sheets, finds unique vendors, and adds missing ones to 'ê±°ë˜ì²˜ì •ë³´' sheet.
        """
        try:
            wb = load_workbook(self.file_path)
            
            # 1. Collect all vendors from monthly sheets
            all_vendors = set()
            months = [7, 8, 9, 10, 11, 12]
            
            for m in months:
                sheet_name = f"{m}ì›”ë¹„ìš©"
                if sheet_name in wb.sheetnames:
                    ws = wb[sheet_name]
                    # Scan Column A (idx 1), skipping first 2 rows
                    for row in ws.iter_rows(min_row=3, min_col=1, max_col=1, values_only=True):
                        val = row[0]
                        if val and isinstance(val, str):
                            all_vendors.add(val)
            
            # 2. Initialize or Load 'ê±°ë˜ì²˜ì •ë³´' sheet
            if 'ê±°ë˜ì²˜ì •ë³´' not in wb.sheetnames:
                ws_info = wb.create_sheet('ê±°ë˜ì²˜ì •ë³´')
                ws_info.append(['Vendor', 'Item']) # Header
                existing_vendors = set()
            else:
                ws_info = wb['ê±°ë˜ì²˜ì •ë³´']
                # Read existing
                existing_vendors = set()
                for row in ws_info.iter_rows(min_row=2, min_col=1, max_col=1, values_only=True):
                    if row[0]: existing_vendors.add(row[0])
            
            # 3. Add new vendors
            new_vendors = all_vendors - existing_vendors
            for v in new_vendors:
                ws_info.append([v, '']) # Default empty item
                
            if new_vendors:
                wb.save(self.file_path)
                return len(new_vendors)
            return 0
            
        except Exception as e:
            print(f"Error syncing vendors: {e}")
            return 0

    def update_vendor_item(self, vendor_name, new_item):
        """
        Updates the 'Item' column for a specific vendor in 'ê±°ë˜ì²˜ì •ë³´' sheet.
        """
        try:
            wb = load_workbook(self.file_path)
            if 'ê±°ë˜ì²˜ì •ë³´' not in wb.sheetnames:
                return False
            
            ws = wb['ê±°ë˜ì²˜ì •ë³´']
            found = False
            
            # Search for vendor
            for row in ws.iter_rows(min_row=2, max_col=2):
                cell_vendor = row[0]
                cell_item = row[1]
                
                if cell_vendor.value == vendor_name:
                    cell_item.value = new_item
                    found = True
                    break
            
            if found:
                wb.save(self.file_path)
                return True
            return False
            
        except Exception as e:
            print(f"Error updating vendor item: {e}")
            return False

    def add_expense(self, date_str: str, item: str, amount: int, category: str = "ê¸°íƒ€"):
        """
        Adds an expense record to the appropriate monthly sheet.
        date_str: "YYYY-MM-DD"
        """
        try:
            # Parse date to find month
            dt = datetime.datetime.strptime(date_str, "%Y-%m-%d")
            month = dt.month
            
            # Map month to sheet name (Need to match Excel sheet names like '9ì›”ë¹„ìš©')
            # The file has '7ì›”ë¹„ìš©' ... '12ì›”ë¹„ìš©'
            sheet_name = f"{month}ì›”ë¹„ìš©"
            
            # Helper to check if sheet exists
            xl = pd.ExcelFile(self.file_path)
            if sheet_name not in xl.sheet_names:
                # Fallback or error?
                # Maybe the file only has 9-12?
                # Let's check available sheets
                if sheet_name not in xl.sheet_names:
                    return {"status": "error", "message": f"Sheet {sheet_name} not found"}
            
            # Load the workbook using openpyxl for editing
            from openpyxl import load_workbook
            wb = load_workbook(self.file_path)
            ws = wb[sheet_name]
            
            # Find first empty row (assuming standard list format)
            # We should append to the bottom.
            # Assuming columns: Date | Item | Amount | Category ...
            # Need to know the column structure of cost sheets.
            # For now, let's append to the end.
            ws.append([date_str, item, amount, category])
            
            wb.save(self.file_path)
            return {"status": "success", "message": f"Added to {sheet_name}"}
            
        except Exception as e:
            print(f"Error adding expense: {e}")
            return {"status": "error", "message": str(e)}
    def parse_upload(self, file_contents: bytes):
        """
        Smart parser that auto-detects card company format and parses accordingly.
        Supports: ë¡¯ë°ì¹´ë“œ, ì‹ í•œì¹´ë“œ, ì‚¼ì„±ì¹´ë“œ, KBêµ­ë¯¼ì¹´ë“œ, í˜„ëŒ€ì¹´ë“œ, ì€í–‰ ì†¡ê¸ˆë‚´ì—­, ì¼ë°˜ í˜•ì‹
        Supports both .xls and .xlsx formats
        """
        import io
        try:
            # Helper function to read excel with fallback engines
            def read_excel_safe(content, **kwargs):
                """Try different engines for .xls/.xlsx compatibility and handle HTML masquerading as Excel"""
                error_list = []
                
                # 1. Try standard Excel engines
                engines = ['openpyxl', 'xlrd', None]
                for engine in engines:
                    try:
                        if engine:
                            return pd.read_excel(io.BytesIO(content), engine=engine, **kwargs)
                        else:
                            return pd.read_excel(io.BytesIO(content), **kwargs)
                    except Exception as e:
                        error_list.append(f"Engine {engine}: {str(e)}")
                        continue
                
                # 2. Try parsing as HTML (common in Korean finance for .xls files)
                try:
                    # read_html does not support 'nrows', remove it if present
                    html_kwargs = kwargs.copy()
                    if 'nrows' in html_kwargs:
                        del html_kwargs['nrows']
                        
                    dfs = pd.read_html(io.BytesIO(content), **html_kwargs)
                    if dfs:
                        # Return the dataframe with the most rows/columns roughly
                        best_df = max(dfs, key=lambda x: x.size)
                        return best_df
                except Exception as e:
                    error_list.append(f"HTML Parser: {str(e)}")
                
                # If all failed
                raise ValueError(f"Failed to read file. Errors: {'; '.join(error_list)}")
            
            # Read the file
            # Note: We skip the 'preview' step with nrows because read_html doesn't support it 
            # and it causes issues. We'll read the whole file and find headers in-memory.
            try:
                df = read_excel_safe(file_contents)
            except Exception as e:
                 return {"status": "error", "message": f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}"}

            # Post-load Header Detection
            # If the first row doesn't look like a header, scan specifically for headers
            cols = [str(c).strip() for c in df.columns.tolist()]
            
            # Keywords to identify header row
            header_keywords = ['ì´ìš©ì¼ì', 'ìŠ¹ì¸ì¼ì', 'ê±°ë˜ì¼ì', 'ë‚ ì§œ', 'Date', 'ì¼ì']
            
            found_header_idx = -1
            
            # Check if current columns are already headers
            if any(k in str(c) for c in cols for k in header_keywords):
                found_header_idx = -2 # Already good
            else:
                # Scan first 20 rows for header
                for i, row in df.head(20).iterrows():
                    row_text = ' '.join([str(v) for v in row.values if pd.notna(v)])
                    if any(k in row_text for k in header_keywords):
                        found_header_idx = i
                        break
            
            # Apply new header if found
            if found_header_idx >= 0:
                # Set row i as header
                new_header = df.iloc[found_header_idx]
                df = df.iloc[found_header_idx + 1:]
                df.columns = new_header
                cols = [str(c).strip() for c in df.columns.tolist()]
                
            # Now proceed with detection
            cols_lower = [c.lower() for c in cols]
            
            # Detect format and map columns
            format_detected = "unknown"
            date_col = None
            item_col = None
            amount_col = None
            category_col = None
            
            # Helper to find column by keywords
            def find_col(keywords):
                for i, c in enumerate(cols):
                    if any(k in c for k in keywords):
                        return cols[i]
                return None
            
            # Pattern 1: ë¡¯ë°ì¹´ë“œ/ì‹ í•œì¹´ë“œ í˜•ì‹ (ì´ìš©ì¼ì, ì´ìš©ê°€ë§¹ì , ì´ìš©ê¸ˆì•¡)
            if find_col(['ì´ìš©ì¼ì', 'ìŠ¹ì¸ì¼ì', 'ê²°ì œì¼ì']):
                format_detected = "card_statement"
                date_col = find_col(['ì´ìš©ì¼ì', 'ìŠ¹ì¸ì¼ì', 'ê²°ì œì¼ì', 'ê±°ë˜ì¼ì'])
                item_col = find_col(['ì´ìš©ê°€ë§¹ì ', 'ê°€ë§¹ì ëª…', 'ê°€ë§¹ì ', 'ì‚¬ìš©ì²˜', 'ì´ìš©ì²˜'])
                amount_col = find_col(['ì´ìš©ê¸ˆì•¡', 'ê²°ì œê¸ˆì•¡', 'ìŠ¹ì¸ê¸ˆì•¡', 'ì‚¬ìš©ê¸ˆì•¡', 'ê¸ˆì•¡'])
                category_col = find_col(['ì—…ì¢…', 'ë¶„ë¥˜', 'ì¹´í…Œê³ ë¦¬'])
            
            # Pattern 1.5: ì‹ í•œì€í–‰/êµ­ë¯¼ì€í–‰ ì†¡ê¸ˆë‚´ì—­ í˜•ì‹ (ê±°ë˜ì¼ì, ì¶œê¸ˆ(ì›), ë‚´ìš©)
            elif find_col(['ê±°ë˜ì¼ì']) and find_col(['ì¶œê¸ˆ']):
                format_detected = "bank_transfer"
                date_col = find_col(['ê±°ë˜ì¼ì'])
                item_col = find_col(['ë‚´ìš©', 'ì ìš”', 'ê±°ë˜ë‚´ìš©', 'ë©”ëª¨'])
                amount_col = find_col(['ì¶œê¸ˆ', 'ì¶œê¸ˆ(ì›)', 'ì¶œê¸ˆì•¡', 'ì´ì²´ê¸ˆì•¡'])
                category_col = None  # Bank statements usually don't have category
                
            # Pattern 2: ì¼ë°˜ ì§€ì¶œ í˜•ì‹ (ë‚ ì§œ, í•­ëª©, ê¸ˆì•¡)
            elif find_col(['ë‚ ì§œ', 'Date', 'ì¼ì']):
                format_detected = "standard"
                date_col = find_col(['ë‚ ì§œ', 'Date', 'ì¼ì'])
                item_col = find_col(['í•­ëª©', 'Item', 'ë‚´ì—­', 'ì‚¬ìš©ì²˜', 'ì ìš”'])
                amount_col = find_col(['ê¸ˆì•¡', 'Amount', 'ë¹„ìš©', 'ì§€ì¶œ'])
                category_col = find_col(['ë¶„ë¥˜', 'Category', 'ì¹´í…Œê³ ë¦¬'])
            
            # Pattern 3: Fallback - use first few columns
            else:
                format_detected = "auto"
                # Try to find date-like column
                for c in cols:
                    if any(x in c for x in ['ì¼', 'date', 'Date', 'ë‚ ']):
                        date_col = c
                        break
                if not date_col and len(cols) > 0:
                    date_col = cols[0]
                    
                # Amount column - look for numbers in column name or data
                for c in cols:
                    if any(x in c for x in ['ê¸ˆì•¡', 'ì›', 'amount', 'Amount', 'ë¹„ìš©']):
                        amount_col = c
                        break
                if not amount_col and len(cols) > 1:
                    # Try to find a numeric column
                    for c in cols[1:]:
                        try:
                            if df[c].dtype in ['int64', 'float64']:
                                amount_col = c
                                break
                        except:
                            pass
                            
                item_col = find_col(['í•­ëª©', 'ê°€ë§¹ì ', 'ë‚´ì—­', 'ì‚¬ìš©ì²˜', 'ì ìš”', 'ìƒí˜¸'])
            
            if not date_col:
                return {"status": "error", "message": "ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ìš©ì¼ì/ë‚ ì§œ/Date)"}
            if not amount_col:
                return {"status": "error", "message": "ê¸ˆì•¡ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ìš©ê¸ˆì•¡/ê¸ˆì•¡/Amount)"}
            
            results = []
            skipped = 0
            
            for idx, row in df.iterrows():
                try:
                    # Parse date
                    d_val = row[date_col]
                    if pd.isna(d_val):
                        skipped += 1
                        continue
                        
                    if isinstance(d_val, (datetime.datetime, datetime.date)):
                        d_str = d_val.strftime("%Y-%m-%d")
                    elif isinstance(d_val, str):
                        # Handle various date formats
                        d_clean = d_val.strip()
                        
                        # Korean format: "2026ë…„ 01ì›” 31ì¼" or "2026ë…„01ì›”31ì¼"
                        if 'ë…„' in d_clean:
                            import re
                            match = re.search(r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼?', d_clean)
                            if match:
                                year, month, day = match.groups()
                                d_str = f"{year}-{int(month):02d}-{int(day):02d}"
                            else:
                                # Only year and month: "2026ë…„ 01ì›”" - skip this row
                                skipped += 1
                                continue
                        else:
                            # Standard formats: 2026.01.31, 2026-01-31, 2026/01/31
                            d_clean = d_clean.replace('.', '-').replace('/', '-')
                            d_str = d_clean[:10]
                    else:
                        d_str = str(d_val)[:10]
                    
                    # Validate date format (must be YYYY-MM-DD with at least 10 chars)
                    if not d_str or len(d_str) < 8 or d_str in ['-', '--', '---']:
                        skipped += 1
                        continue
                    # Additional check: must contain digits
                    if not any(c.isdigit() for c in d_str):
                        skipped += 1
                        continue
                    
                    # Parse amount
                    amt = row[amount_col]
                    if pd.isna(amt):
                        skipped += 1
                        continue
                    
                    # Handle various number formats: 7,900 / 7900 / 7900.0
                    if isinstance(amt, (int, float)):
                        amt = int(abs(amt))
                    else:
                        amt_str = str(amt).replace(',', '').replace('ì›', '').strip()
                        try:
                            amt = int(abs(float(amt_str)))
                        except:
                            skipped += 1
                            continue
                    
                    if amt == 0:
                        skipped += 1
                        continue
                    
                    # Parse item/vendor
                    item = "ë¯¸ì§€ì •"
                    if item_col and pd.notna(row.get(item_col)):
                        item = str(row[item_col]).strip()
                    
                    # Parse category
                    cat = "ê¸°íƒ€"
                    if category_col and pd.notna(row.get(category_col)):
                        cat = str(row[category_col]).strip()
                    
                    results.append({
                        "date": d_str,
                        "item": item,
                        "amount": amt,
                        "category": cat
                    })
                    
                except Exception as row_e:
                    skipped += 1
                    continue
            
            if not results:
                return {"status": "error", "message": f"íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (í˜•ì‹: {format_detected}, ìŠ¤í‚µ: {skipped}í–‰)"}
                    
            return {
                "status": "success", 
                "data": results,
                "format": format_detected,
                "parsed": len(results),
                "skipped": skipped
            }
            
        except Exception as e:
            import traceback
            return {"status": "error", "message": f"Excel íŒŒì‹± ì˜¤ë¥˜: {str(e)}"}

    # --- Card company â†’ vendor name mapping for revenue upload ---
    CARD_VENDOR_MAP = {
        'ì‹ í•œì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  ì‹ í•œì¹´ë“œ',
        'KBì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  êµ­ë¯¼ì¹´ë“œ',
        'KBêµ­ë¯¼ì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  êµ­ë¯¼ì¹´ë“œ',
        'ë¹„ì”¨ì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  BCì¹´ë“œ',
        'í˜„ëŒ€ì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  í˜„ëŒ€ì¹´ë“œ',
        'í•˜ë‚˜ì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  í•˜ë‚˜ì¹´ë“œ',
        'í•˜ë‚˜êµ¬ì™¸í™˜': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  í•˜ë‚˜ì¹´ë“œ',
        'ì‚¼ì„±ì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  ì‚¼ì„±ì¹´ë“œ',
        'ë¡¯ë°ì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  ë¡¯ë°ì¹´ë“œ',
        'ì‹ ë¡¯ë°ì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  ë¡¯ë°ì¹´ë“œ',
        'ìš°ë¦¬ì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  ìš°ë¦¬ì¹´ë“œ',
        'ë†í˜‘ì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  ë†í˜‘ì¹´ë“œ',
        'NHì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  ë†í˜‘ì¹´ë“œ',
        'NHë†í˜‘ì¹´ë“œ': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  ë†í˜‘ì¹´ë“œ',
        'ì¹´ì¹´ì˜¤í˜ì´': 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  ì¹´ì¹´ì˜¤í˜ì´',
    }
    CASH_VENDOR_NAME = 'ì†Œë‹´ê¹€ë°¥ ê±´ëŒ€ë³¸ì  í˜„ê¸ˆë§¤ì¶œ'

    def parse_revenue_upload(self, file_contents: bytes):
        """
        Smart revenue file parser. Auto-detects file type and returns structured data.
        
        Supported formats:
        1. POS ì¼ìë³„ ë§¤ì¶œë‚´ì—­ (ì´ë§¤ì¶œ, í˜„ê¸ˆ, ì¹´ë“œ breakdown per day)
        2. ì¹´ë“œìƒì„¸ë§¤ì¶œë‚´ì—­ (individual card transactions)
        3. ì›”ë³„ ì¹´ë“œë§¤ì¶œë‚´ì—­ (monthly card summary)
        
        Returns:
            dict with keys: status, file_type, data[], summary{}
            data items: { date, amount, vendor_name, note }
        """
        import io
        
        try:
            # Try to read the file with different engines
            df = None
            for engine_name in ['openpyxl', 'xlrd', None]:
                try:
                    if engine_name:
                        df = pd.read_excel(io.BytesIO(file_contents), header=None, engine=engine_name)
                    else:
                        df = pd.read_excel(io.BytesIO(file_contents), header=None)
                    break
                except Exception:
                    continue
            
            if df is None:
                # Try HTML (Korean .xls files are often HTML)
                try:
                    dfs = pd.read_html(io.BytesIO(file_contents))
                    if dfs:
                        df = max(dfs, key=lambda x: x.size)
                except Exception:
                    pass
            
            if df is None:
                return {"status": "error", "message": "íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            # --- Detect file type by scanning first few rows ---
            # Priority 1: Known specific formats (exact keyword match)
            first_rows_text = ''
            for i in range(min(5, len(df))):
                row_vals = [str(v) for v in df.iloc[i].tolist() if pd.notna(v)]
                first_rows_text += ' '.join(row_vals) + ' '
            
            if 'ë§¤ì¶œì¼ì' in first_rows_text and ('ì´ë§¤ì¶œ' in first_rows_text or 'ìˆœë§¤ì¶œ' in first_rows_text):
                return self._parse_pos_daily_revenue(df)
            elif 'ê¸°ê°„ë³„ ìŠ¹ì¸ë‚´ì—­' in first_rows_text or ('No.' in first_rows_text and 'ì¹´ë“œì‚¬' in first_rows_text and 'ìŠ¹ì¸ê¸ˆì•¡' in first_rows_text):
                return self._parse_card_detail_revenue(df)
            elif 'ì›”ë³„ ìŠ¹ì¸ë‚´ì—­' in first_rows_text:
                return self._parse_card_summary_revenue(df)
            
            # Priority 1.5: Delivery app packed format (ì¿ íŒ¡ì´ì¸  ë“±)
            # Single-column format like: "1. 2026.02.27ê¸°ë³¸ì •ì‚°286,792ì›724,366ì›"
            if len(df.columns) <= 2 and ('ê¸°ë³¸ì •ì‚°' in first_rows_text or 'ì¸ì¶œ' in first_rows_text):
                return self._parse_delivery_settlement(df)
            
            # Priority 2: Universal pattern-based detection (any POS vendor)
            return self._parse_universal_revenue(df, file_contents)
        
        except Exception as e:
            import traceback
            return {"status": "error", "message": f"ë§¤ì¶œ íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {str(e)}"}

    def _parse_delivery_settlement(self, df):
        """
        Parse delivery app settlement files with packed single-column format.
        Supports: ì¿ íŒ¡ì´ì¸ , and similar formats.
        
        Format: "1. 2026.02.27ì¸ì¶œ-724,366ì›0ì›"
        'ì¸ì¶œ' entries = actual money deposited to bank = revenue for P&L.
        'ê¸°ë³¸ì •ì‚°' = Coupang-side receipt (not yet deposited), skipped.
        """
        import re
        
        # Regex: number. date type amountì› balanceì›
        pattern = re.compile(
            r'\d+\.\s*'
            r'(\d{4}\.\d{2}\.\d{2})'
            r'(ê¸°ë³¸ì •ì‚°|ì¸ì¶œ|ë³´ì •|ê¸°íƒ€)'
            r'(-?[\d,]+)ì›'
        )
        
        daily_revenue = {}
        total_count = 0
        
        for _, row in df.iterrows():
            text = str(row.iloc[0])
            match = pattern.search(text)
            if not match:
                continue
            
            date_str = match.group(1).replace('.', '-')  # 2026.02.27 -> 2026-02-27
            tx_type = match.group(2)
            amount_str = match.group(3).replace(',', '')
            
            try:
                amount = int(amount_str)
            except ValueError:
                continue
            
            # ì¸ì¶œ = actual deposit to bank account = revenue for P&L
            # Amount is negative in source, so use abs()
            if tx_type == 'ì¸ì¶œ':
                daily_revenue[date_str] = daily_revenue.get(date_str, 0) + abs(amount)
                total_count += 1
        
        results = []
        total_amount = 0
        date_range = [None, None]
        
        for date_str in sorted(daily_revenue.keys()):
            amount = daily_revenue[date_str]
            if date_range[0] is None:
                date_range[0] = date_str
            date_range[1] = date_str
            
            results.append({
                'date': date_str,
                'amount': amount,
                'vendor_name': 'ì¿ íŒ¡ì´ì¸ ',
                'note': 'ì¿ íŒ¡ì´ì¸  ì •ì‚°',
                'payment_type': 'delivery',
            })
            total_amount += amount
        
        return {
            "status": "success",
            "file_type": "delivery_settlement",
            "file_type_label": "ğŸ›µ ë°°ë‹¬ì•± ì •ì‚° (ì¿ íŒ¡ì´ì¸ )",
            "data": results,
            "summary": {
                "total_amount": total_amount,
                "record_count": len(results),
                "transaction_count": total_count,
                "date_range": date_range,
            }
        }

    # â”€â”€â”€ Keyword sets for universal column detection â”€â”€â”€
    DATE_KEYWORDS = ['ì¼ì', 'ë‚ ì§œ', 'ì¼ì‹œ', 'date', 'ë§¤ì¶œì¼']
    AMOUNT_KEYWORDS = ['ê¸ˆì•¡', 'ë§¤ì¶œ', 'ìŠ¹ì¸ê¸ˆì•¡', 'ë§¤ì¶œì•¡', 'ê²°ì œê¸ˆì•¡', 'ìŠ¹ì¸ì•¡', 'amount']
    CARD_CORP_KEYWORDS = ['ì¹´ë“œì‚¬', 'ë§¤ì…ì‚¬', 'ì¹´ë“œì‚¬ëª…', 'ë§¤ì…ì‚¬ëª…', 'ë§¤ì…ì¹´ë“œì‚¬', 'ë°œê¸‰ì‚¬', 'ì¹´ë“œì¢…ë¥˜']
    CASH_KEYWORDS = ['í˜„ê¸ˆ', 'cash', 'í˜„ê¸ˆë§¤ì¶œ']
    CARD_TOTAL_KEYWORDS = ['ì¹´ë“œë§¤ì¶œ', 'ì¹´ë“œí•©ê³„', 'ì¹´ë“œ', 'ì‹ ìš©ì¹´ë“œ']
    STATUS_KEYWORDS = ['êµ¬ë¶„', 'ìŠ¹ì¸êµ¬ë¶„', 'ìƒíƒœ', 'ê±°ë˜êµ¬ë¶„', 'ìœ í˜•']
    TOTAL_KEYWORDS = ['ì´ë§¤ì¶œ', 'ì´ì•¡', 'í•©ê³„', 'ìˆœë§¤ì¶œ', 'ì´í•©', 'total']

    def _parse_universal_revenue(self, df, file_contents):
        """
        Universal revenue file parser â€” works with any POS vendor format.
        
        Strategy:
        1. Auto-detect header row by scanning for date/amount keywords
        2. Map columns flexibly using broad keyword sets
        3. Classify file as 'daily_summary' or 'card_detail' by data pattern
        4. Parse and return structured data
        """
        import io
        
        # Step 1: Find header row
        header_row = -1
        for i in range(min(10, len(df))):
            row_vals = [str(v).strip() for v in df.iloc[i].tolist() if pd.notna(v)]
            row_text = ' '.join(row_vals)
            has_date = any(k in row_text for k in self.DATE_KEYWORDS)
            has_amount = any(k in row_text for k in self.AMOUNT_KEYWORDS)
            if has_date and has_amount:
                header_row = i
                break
        
        if header_row < 0:
            return {"status": "error", "message": "ë‚ ì§œ/ê¸ˆì•¡ ì»¬ëŸ¼ì„ ìë™ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í—¤ë” í–‰ì— 'ì¼ì', 'ê¸ˆì•¡' ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."}
        
        # Re-read with proper header
        new_header = [str(v).strip() if pd.notna(v) else f'col_{j}' for j, v in enumerate(df.iloc[header_row])]
        data_df = df.iloc[header_row + 1:].copy()
        data_df.columns = new_header
        cols = list(data_df.columns)
        
        # Step 2: Map columns using keyword matching
        def find_col(keywords, exclude=None):
            for c in cols:
                cl = c.lower() if c else ''
                if any(k in c or k in cl for k in keywords):
                    if exclude and any(ex in c for ex in exclude):
                        continue
                    return c
            return None
        
        date_col = find_col(self.DATE_KEYWORDS)
        amount_col = find_col(self.AMOUNT_KEYWORDS, exclude=['í˜„ê¸ˆ', 'cash'])
        card_corp_col = find_col(self.CARD_CORP_KEYWORDS)
        status_col = find_col(self.STATUS_KEYWORDS)
        
        # Look for separate cash/card total columns (daily summary files)
        cash_col = find_col(self.CASH_KEYWORDS)
        card_total_col = find_col(self.CARD_TOTAL_KEYWORDS, exclude=['ì¹´ë“œì‚¬'])
        total_col = find_col(self.TOTAL_KEYWORDS)
        
        if not date_col:
            return {"status": "error", "message": f"ë‚ ì§œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°ì§€ëœ ì»¬ëŸ¼: {cols[:15]}"}
        if not amount_col and not total_col and not (cash_col or card_total_col):
            return {"status": "error", "message": f"ê¸ˆì•¡ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°ì§€ëœ ì»¬ëŸ¼: {cols[:15]}"}
        
        print(f"[Universal] date={date_col}, amount={amount_col}, card_corp={card_corp_col}, "
              f"status={status_col}, cash={cash_col}, card_total={card_total_col}, total={total_col}")

        # Step 3: Classify file type by data pattern
        # Count date frequency â€” daily summary has ~1 row/date, detail has many
        date_counts = {}
        sample_size = min(100, len(data_df))
        for i in range(sample_size):
            dv = data_df.iloc[i].get(date_col)
            if pd.notna(dv):
                ds = str(dv)[:10]
                date_counts[ds] = date_counts.get(ds, 0) + 1
        
        avg_rows_per_date = (sum(date_counts.values()) / len(date_counts)) if date_counts else 1
        
        # If card company column exists AND avg > 2 rows per date â†’ card transaction detail
        # If separate cash/card columns exist OR avg â‰ˆ 1 â†’ daily summary
        is_daily_summary = (cash_col or card_total_col or total_col) and not card_corp_col and avg_rows_per_date < 3
        is_card_detail = card_corp_col is not None and avg_rows_per_date >= 2
        
        # Fallback: if card corp column exists, treat as detail regardless
        if card_corp_col and not is_daily_summary:
            is_card_detail = True
        
        if is_daily_summary:
            return self._parse_universal_daily_summary(data_df, date_col, cash_col, card_total_col, total_col)
        elif is_card_detail:
            return self._parse_universal_card_detail(data_df, date_col, amount_col, card_corp_col, status_col)
        else:
            # Generic: treat as card detail if possible, otherwise daily
            if amount_col:
                return self._parse_universal_card_detail(data_df, date_col, amount_col, card_corp_col, status_col)
            return {"status": "error", "message": f"íŒŒì¼ ìœ í˜•ì„ ë¶„ë¥˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼: {cols[:15]}"}

    def _parse_universal_daily_summary(self, df, date_col, cash_col, card_col, total_col):
        """Parse a daily summary file (one row per day, cash/card breakdown)."""
        results = []
        total_amount = 0
        date_range = [None, None]
        
        def clean_num(val):
            if pd.isna(val): return 0
            try: return int(float(str(val).replace(',', '').replace('ì›', '')))
            except: return 0
        
        for _, row in df.iterrows():
            date_val = row.get(date_col)
            if pd.isna(date_val): continue
            
            if isinstance(date_val, datetime.datetime):
                date_str = date_val.strftime('%Y-%m-%d')
            else:
                ds = str(date_val).strip().replace('.', '-').replace('/', '-')
                if len(ds) >= 10:
                    date_str = ds[:10]
                elif len(ds) >= 8 and ds[:4].isdigit():
                    date_str = f"{ds[:4]}-{ds[4:6]}-{ds[6:8]}"
                else:
                    continue
            
            # Validate date
            try:
                datetime.datetime.strptime(date_str[:10], '%Y-%m-%d')
            except:
                continue
            
            if date_range[0] is None: date_range[0] = date_str
            date_range[1] = date_str
            
            cash = clean_num(row.get(cash_col)) if cash_col else 0
            card = clean_num(row.get(card_col)) if card_col else 0
            total = clean_num(row.get(total_col)) if total_col else 0
            
            # If only total is available (no cash/card breakdown)
            if total > 0 and cash == 0 and card == 0:
                card = total  # Assume total is card if no breakdown
            
            # If we have total but no separate, use ratio
            if total > 0 and (cash + card) > 0 and abs(total - (cash + card)) > 100:
                # Total includes VAT or fees â€” scale proportionally
                ratio = total / (cash + card) if (cash + card) > 0 else 1
                cash = int(cash * ratio)
                card = int(card * ratio)
            
            if cash > 0:
                results.append({
                    'date': date_str, 'amount': cash,
                    'vendor_name': self.CASH_VENDOR_NAME,
                    'note': 'í˜„ê¸ˆë§¤ì¶œ', 'payment_type': 'cash',
                })
            if card > 0:
                results.append({
                    'date': date_str, 'amount': card,
                    'vendor_name': 'ì¹´ë“œë§¤ì¶œ(í†µí•©)',
                    'note': 'ì¹´ë“œë§¤ì¶œ', 'payment_type': 'card',
                })
            total_amount += (cash + card)
        
        return {
            "status": "success",
            "file_type": "pos_daily",
            "file_type_label": "ğŸ“Š ì¼ìë³„ ë§¤ì¶œë‚´ì—­ (ìë™ê°ì§€)",
            "data": results,
            "summary": {
                "total_amount": total_amount,
                "record_count": len(results),
                "date_range": date_range,
            }
        }
    
    def _parse_universal_card_detail(self, df, date_col, amount_col, card_corp_col, status_col):
        """Parse a card transaction detail file (many rows per day)."""
        daily_card = {}
        total_count = 0
        cancel_count = 0
        
        for _, row in df.iterrows():
            date_val = row.get(date_col)
            amount_val = row.get(amount_col) if amount_col else None
            
            if pd.isna(date_val) or (amount_val is not None and pd.isna(amount_val)):
                continue
            
            # Parse date
            if isinstance(date_val, datetime.datetime):
                date_str = date_val.strftime('%Y-%m-%d')
            else:
                ds = str(date_val).strip().replace('.', '-').replace('/', '-')
                if '-' in ds:
                    date_str = ds[:10]
                elif len(ds) >= 8 and ds[:4].isdigit():
                    date_str = f"{ds[:4]}-{ds[4:6]}-{ds[6:8]}"
                else:
                    continue
            
            # Validate date
            try:
                datetime.datetime.strptime(date_str[:10], '%Y-%m-%d')
            except:
                continue
            
            # Parse amount
            try:
                amt = int(float(str(amount_val).replace(',', '').replace('ì›', '')))
            except (ValueError, TypeError):
                continue
            
            # Check cancellation
            if status_col:
                tx_type = str(row.get(status_col, '')).strip()
                if 'ì·¨ì†Œ' in tx_type:
                    amt = -amt
                    cancel_count += 1
                else:
                    total_count += 1
            else:
                total_count += 1
            
            # Card company name
            if card_corp_col and pd.notna(row.get(card_corp_col)):
                card_name = str(row.get(card_corp_col)).strip()
            else:
                card_name = 'ê¸°íƒ€ì¹´ë“œ'
            
            key = (date_str, card_name)
            daily_card[key] = daily_card.get(key, 0) + amt
        
        results = []
        total_amount = 0
        date_range = [None, None]
        
        for (date_str, card_name), amount in sorted(daily_card.items()):
            if amount <= 0:
                continue
            
            vendor_name = self.CARD_VENDOR_MAP.get(card_name, f'ê¸°íƒ€ì¹´ë“œ({card_name})')
            
            if date_range[0] is None: date_range[0] = date_str
            date_range[1] = date_str
            
            results.append({
                'date': date_str, 'amount': amount,
                'vendor_name': vendor_name,
                'note': f'ì¹´ë“œë§¤ì¶œ({card_name})',
                'payment_type': 'card',
                'card_company': card_name,
            })
            total_amount += amount
        
        return {
            "status": "success",
            "file_type": "card_detail",
            "file_type_label": "ğŸ’³ ì¹´ë“œë§¤ì¶œ ìƒì„¸ (ìë™ê°ì§€)",
            "data": results,
            "summary": {
                "total_amount": total_amount,
                "record_count": len(results),
                "transaction_count": total_count,
                "cancel_count": cancel_count,
                "date_range": date_range,
            }
        }

    def _parse_pos_card_detail_revenue(self, df):
        """Parse POS system card sales detail file (ì‹ ìš©ì¹´ë“œ ë§¤ì¶œë‚´ì—­).
        Columns: NO, êµ¬ë¶„, ì˜ì—…ì¼ì, ê±°ë˜ì¼ì, ê±°ë˜ì‹œê°„, í¬ìŠ¤ë²ˆí˜¸, ìŠ¹ì¸ë²ˆí˜¸,
                 ì¹´ë“œë²ˆí˜¸, ì¹´ë“œì‚¬ëª…, ë§¤ì…ì‚¬ëª…, ìŠ¹ì¸ê¸ˆì•¡, í• ë¶€, ìŠ¹ì¸êµ¬ë¶„, ...
        """
        # Find header row
        header_row = 0
        for i in range(min(5, len(df))):
            row_vals = [str(v) for v in df.iloc[i].tolist() if pd.notna(v)]
            row_text = ' '.join(row_vals)
            if ('ì˜ì—…ì¼ì' in row_text or 'ê±°ë˜ì¼ì' in row_text) and 'ìŠ¹ì¸ê¸ˆì•¡' in row_text:
                header_row = i
                break

        # Set header
        new_header = [str(v).strip() if pd.notna(v) else f'col_{j}' for j, v in enumerate(df.iloc[header_row])]
        data_df = df.iloc[header_row + 1:].copy()
        data_df.columns = new_header

        # Resolve column names
        date_col = None
        for c in ['ì˜ì—…ì¼ì', 'ê±°ë˜ì¼ì', 'ìŠ¹ì¸ì¼ì']:
            if c in data_df.columns:
                date_col = c
                break

        card_col = None
        for c in ['ì¹´ë“œì‚¬ëª…', 'ë§¤ì…ì‚¬ëª…', 'ë§¤ì…ì¹´ë“œì‚¬']:
            if c in data_df.columns:
                card_col = c
                break

        status_col = None
        for c in ['êµ¬ë¶„', 'ìŠ¹ì¸êµ¬ë¶„']:
            if c in data_df.columns:
                status_col = c
                break

        if not date_col or 'ìŠ¹ì¸ê¸ˆì•¡' not in data_df.columns:
            return {"status": "error", "message": "ì‹ ìš©ì¹´ë“œ ë§¤ì¶œë‚´ì—­ ì»¬ëŸ¼ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        daily_card = {}
        total_count = 0
        cancel_count = 0

        for _, row in data_df.iterrows():
            date_val = row.get(date_col)
            amount_val = row.get('ìŠ¹ì¸ê¸ˆì•¡')

            if pd.isna(date_val) or pd.isna(amount_val):
                continue

            # Parse date
            if isinstance(date_val, datetime.datetime):
                date_str = date_val.strftime('%Y-%m-%d')
            else:
                ds = str(date_val).strip()
                if '-' in ds:
                    date_str = ds[:10]
                elif len(ds) >= 8 and ds[:4].isdigit():
                    date_str = f"{ds[:4]}-{ds[4:6]}-{ds[6:8]}"
                else:
                    continue

            # Parse amount
            try:
                amt = int(float(str(amount_val).replace(',', '')))
            except (ValueError, TypeError):
                continue

            # Check cancellation
            tx_type = str(row.get(status_col, '')).strip() if status_col else ''
            if 'ì·¨ì†Œ' in tx_type:
                amt = -amt
                cancel_count += 1
            else:
                total_count += 1

            card_name = str(row.get(card_col, 'ê¸°íƒ€ì¹´ë“œ')).strip() if card_col else 'ê¸°íƒ€ì¹´ë“œ'
            key = (date_str, card_name)
            daily_card[key] = daily_card.get(key, 0) + amt

        results = []
        total_amount = 0
        date_range = [None, None]

        for (date_str, card_name), amount in sorted(daily_card.items()):
            if amount <= 0:
                continue

            vendor_name = self.CARD_VENDOR_MAP.get(card_name, f'ê¸°íƒ€ì¹´ë“œ({card_name})')

            if date_range[0] is None:
                date_range[0] = date_str
            date_range[1] = date_str

            results.append({
                'date': date_str,
                'amount': amount,
                'vendor_name': vendor_name,
                'note': f'ì¹´ë“œë§¤ì¶œ({card_name})',
                'payment_type': 'card',
                'card_company': card_name,
            })
            total_amount += amount

        return {
            "status": "success",
            "file_type": "card_detail",
            "file_type_label": "ğŸ’³ ì‹ ìš©ì¹´ë“œ ë§¤ì¶œë‚´ì—­ (POS)",
            "data": results,
            "summary": {
                "total_amount": total_amount,
                "record_count": len(results),
                "transaction_count": total_count,
                "cancel_count": cancel_count,
                "date_range": date_range,
            }
        }

    def _parse_pos_daily_revenue(self, df):
        """Parse POS daily revenue file (File 3 format)."""
        # Find header row with 'ë§¤ì¶œì¼ì'
        header_row = 0
        for i in range(min(5, len(df))):
            row_vals = [str(v) for v in df.iloc[i].tolist() if pd.notna(v)]
            if 'ë§¤ì¶œì¼ì' in row_vals:
                header_row = i
                break
        
        results = []
        total_amount = 0
        date_range = [None, None]
        data_start = header_row + 2  # skip main + sub header
        
        for i in range(data_start, len(df)):
            row = df.iloc[i]
            date_val = row.iloc[0]
            
            if pd.isna(date_val) or str(date_val).startswith('í•©'):
                continue
            
            if isinstance(date_val, datetime.datetime):
                date_str = date_val.strftime('%Y-%m-%d')
            else:
                date_str = str(date_val)[:10]
            
            total = int(row.iloc[6]) if pd.notna(row.iloc[6]) and row.iloc[6] != 0 else 0
            cash_net = int(row.iloc[14]) if pd.notna(row.iloc[14]) and row.iloc[14] != 0 else 0
            card_net = int(row.iloc[15]) if pd.notna(row.iloc[15]) and row.iloc[15] != 0 else 0
            
            if total == 0:
                continue
            
            # FIX: User wants Gross Sales (inc. VAT).
            # iloc[6] is Total Gross. iloc[14/15] are Net.
            # We calculate ratio to scale Net -> Gross.
            net_sum = cash_net + card_net
            vat_ratio = (total / net_sum) if net_sum > 0 else 1.0
            
            # If ratio is close to 1.1, apply it. If it's 1.0, data is already Gross.
            # Just apply generally to align with Total Gross.
            cash = int(cash_net * vat_ratio)
            card = int(card_net * vat_ratio)

            if date_range[0] is None:
                date_range[0] = date_str
            date_range[1] = date_str
            
            if cash > 0:
                results.append({
                    'date': date_str,
                    'amount': cash,
                    'vendor_name': self.CASH_VENDOR_NAME,
                    'note': 'í˜„ê¸ˆë§¤ì¶œ',
                    'payment_type': 'cash',
                })
            
            if card > 0:
                results.append({
                    'date': date_str,
                    'amount': card,
                    'vendor_name': 'ì¹´ë“œë§¤ì¶œ(í†µí•©)',
                    'note': 'ì¹´ë“œë§¤ì¶œ',
                    'payment_type': 'card',
                })
            
            total_amount += (cash + card)
        
        return {
            "status": "success",
            "file_type": "pos_daily",
            "file_type_label": "ğŸ“Š POS ì¼ìë³„ ë§¤ì¶œë‚´ì—­",
            "data": results,
            "summary": {
                "total_amount": total_amount,
                "record_count": len(results),
                "date_range": date_range,
            }
        }

    def _parse_card_detail_revenue(self, df):
        """Parse card transaction detail file (File 2 format)."""
        header_row = 0
        for i in range(min(5, len(df))):
            row_vals = [str(v) for v in df.iloc[i].tolist() if pd.notna(v)]
            if 'No.' in row_vals or ('êµ¬ë¶„' in row_vals and 'ì¹´ë“œì‚¬' in row_vals):
                header_row = i
                break
        
        data_start = header_row + 1
        daily_card = {}
        total_count = 0
        cancel_count = 0
        
        for i in range(data_start, len(df)):
            row = df.iloc[i]
            date_val = row.iloc[2]
            card_company = row.iloc[4]
            tx_type = row.iloc[1]
            amount = row.iloc[8]
            
            if pd.isna(date_val) or pd.isna(amount):
                continue
            
            if isinstance(date_val, datetime.datetime):
                date_str = date_val.strftime('%Y-%m-%d')
            else:
                date_str = str(date_val)[:10]
            
            try:
                amt = int(float(str(amount).replace(',', '')))
            except (ValueError, TypeError):
                continue
            
            if str(tx_type) == 'ì·¨ì†Œ':
                amt = -amt
                cancel_count += 1
            else:
                total_count += 1
            
            card_name = str(card_company).strip() if pd.notna(card_company) else 'ê¸°íƒ€ì¹´ë“œ'
            key = (date_str, card_name)
            daily_card[key] = daily_card.get(key, 0) + amt
        
        results = []
        total_amount = 0
        date_range = [None, None]
        
        for (date_str, card_name), amount in sorted(daily_card.items()):
            if amount <= 0:
                continue
            
            vendor_name = self.CARD_VENDOR_MAP.get(card_name, f'ê¸°íƒ€ì¹´ë“œ({card_name})')
            
            if date_range[0] is None:
                date_range[0] = date_str
            date_range[1] = date_str
            
            results.append({
                'date': date_str,
                'amount': amount,
                'vendor_name': vendor_name,
                'note': f'ì¹´ë“œë§¤ì¶œ({card_name})',
                'payment_type': 'card',
                'card_company': card_name,
            })
            total_amount += amount
        
        return {
            "status": "success",
            "file_type": "card_detail",
            "file_type_label": "ğŸ’³ ì¹´ë“œ ìƒì„¸ë§¤ì¶œë‚´ì—­",
            "data": results,
            "summary": {
                "total_amount": total_amount,
                "record_count": len(results),
                "transaction_count": total_count,
                "cancel_count": cancel_count,
                "date_range": date_range,
            }
        }

    def _parse_card_summary_revenue(self, df):
        """Parse monthly card summary file (File 1 format)."""
        results = []
        total_amount = 0
        
        for i in range(len(df)):
            row = df.iloc[i]
            val = str(row.iloc[0])
            
            if len(val) >= 7 and val[4] == '-' and val[:4].isdigit():
                year_month = val[:7]
                amount = row.iloc[1]
                
                if pd.notna(amount):
                    try:
                        amt = int(float(str(amount).replace(',', '')))
                    except (ValueError, TypeError):
                        continue
                    
                    approval_total = int(float(str(row.iloc[3]).replace(',', ''))) if pd.notna(row.iloc[3]) else 0
                    approval_count = int(float(str(row.iloc[4]).replace(',', ''))) if pd.notna(row.iloc[4]) else 0
                    cancel_total = int(float(str(row.iloc[5]).replace(',', ''))) if pd.notna(row.iloc[5]) else 0
                    cancel_count = int(float(str(row.iloc[6]).replace(',', ''))) if pd.notna(row.iloc[6]) else 0
                    
                    results.append({
                        'year_month': year_month,
                        'net_amount': amt,
                        'approval_total': approval_total,
                        'approval_count': approval_count,
                        'cancel_total': cancel_total,
                        'cancel_count': cancel_count,
                    })
                    total_amount += amt
        
        return {
            "status": "success",
            "file_type": "card_summary",
            "file_type_label": "ğŸ“ˆ ì›”ë³„ ì¹´ë“œë§¤ì¶œ ìš”ì•½",
            "data": results,
            "summary": {
                "total_amount": total_amount,
                "months": len(results),
            },
            "message": "ì›”ë³„ ì¹´ë“œë§¤ì¶œ ìš”ì•½ ë°ì´í„°ì…ë‹ˆë‹¤. ìƒì„¸ ë§¤ì¶œ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ë ¤ë©´ 'ì¹´ë“œìƒì„¸ë§¤ì¶œë‚´ì—­' ë˜ëŠ” 'POS ì¼ìë³„ ë§¤ì¶œ' íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”."
        }
